{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import TfidfModel, LsiModel\n",
    "from gensim.models.ldamodel import LdaModel\n",
    "from gensim import corpora\n",
    "from gensim import matutils\n",
    "\n",
    "from collections import defaultdict\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Twitter batch. File has 6 tab delimited columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = \"/Users/Orest/Desktop/Big Data and Text Analytics/FP/\"\n",
    "filename = \"twitter_out.txt\"\n",
    "filepath = path + filename\n",
    "tweet_df = pd.read_table(filepath, delimiter = '\\t', header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>language</th>\n",
       "      <th>date</th>\n",
       "      <th>user</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>878033865981521920</td>\n",
       "      <td>en</td>\n",
       "      <td>Thu Jun 22 23:36:01 +0000 2017</td>\n",
       "      <td>NewMetaphor00</td>\n",
       "      <td>United States</td>\n",
       "      <td>RT @HdxAcademy: We congratulate @UChicago &amp;amp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>878035512405114880</td>\n",
       "      <td>en</td>\n",
       "      <td>Thu Jun 22 23:42:33 +0000 2017</td>\n",
       "      <td>MORPaleo</td>\n",
       "      <td>Bozeman, MT</td>\n",
       "      <td>Great visit from @UChicago students #PaulSeren...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>878035797345054722</td>\n",
       "      <td>en</td>\n",
       "      <td>Thu Jun 22 23:43:41 +0000 2017</td>\n",
       "      <td>hbcfl</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>#thursdaythought: “Shadowing attorneys this we...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>878036950170468352</td>\n",
       "      <td>en</td>\n",
       "      <td>Thu Jun 22 23:48:16 +0000 2017</td>\n",
       "      <td>GET_AWAY_TRIKE</td>\n",
       "      <td>ブルースター首都ユニオン</td>\n",
       "      <td>RT @MORPaleo: Great visit from @UChicago stude...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>878039761994227712</td>\n",
       "      <td>en</td>\n",
       "      <td>Thu Jun 22 23:59:27 +0000 2017</td>\n",
       "      <td>C_Ghillie</td>\n",
       "      <td>New York, USA</td>\n",
       "      <td>@AriDavidPaul Curious if u knew @NateSilver538...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   id language                            date  \\\n",
       "0  878033865981521920       en  Thu Jun 22 23:36:01 +0000 2017   \n",
       "1  878035512405114880       en  Thu Jun 22 23:42:33 +0000 2017   \n",
       "2  878035797345054722       en  Thu Jun 22 23:43:41 +0000 2017   \n",
       "3  878036950170468352       en  Thu Jun 22 23:48:16 +0000 2017   \n",
       "4  878039761994227712       en  Thu Jun 22 23:59:27 +0000 2017   \n",
       "\n",
       "             user       location  \\\n",
       "0   NewMetaphor00  United States   \n",
       "1        MORPaleo    Bozeman, MT   \n",
       "2           hbcfl    Los Angeles   \n",
       "3  GET_AWAY_TRIKE   ブルースター首都ユニオン   \n",
       "4       C_Ghillie  New York, USA   \n",
       "\n",
       "                                                text  \n",
       "0  RT @HdxAcademy: We congratulate @UChicago &amp...  \n",
       "1  Great visit from @UChicago students #PaulSeren...  \n",
       "2  #thursdaythought: “Shadowing attorneys this we...  \n",
       "3  RT @MORPaleo: Great visit from @UChicago stude...  \n",
       "4  @AriDavidPaul Curious if u knew @NateSilver538...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rename Columns\n",
    "tweet_df.columns = [\"id\", \"language\", \"date\", \"user\", \"location\", \"text\"]\n",
    "tweet_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     34372\n",
       "unique        1\n",
       "top          en\n",
       "freq      34372\n",
       "Name: language, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if foreign language tweets are present\n",
    "tweet_df.language.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All tweets are in English so no action is necessary here. Also notice that count of tweets is ~35K."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Text preparation/cleanup for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tweet_list_raw = tweet_df.text.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Text cleaning\n",
    "# Remove http\n",
    "link_pttrn = r\"http\\S+\"\n",
    "tweet_list = [re.sub(link_pttrn, \"\", tweet) for tweet in tweet_list_raw]\n",
    "\n",
    "# Remove non-letter sequences\n",
    "nl_pttrn = r\"[^a-zA-Z']+\"\n",
    "tweet_list = [re.sub(nl_pttrn, \" \", tweet) for tweet in tweet_list]\n",
    "\n",
    "# Remove white space at beginning and end of document\n",
    "ws_pttrn = r\"(^ | $)\"\n",
    "tweet_list = [re.sub(ws_pttrn, \"\", tweet) for tweet in tweet_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'RT @UChicago: Exploring the legacy of #UChicago scholar Maria Goeppert Mayer, winner of 1963 @NobelPrize in Physics: https://t.co/KjuVi7VqLa'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pre-processing\n",
    "tweet_list_raw[500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'RT UChicago Exploring the legacy of UChicago scholar Maria Goeppert Mayer winner of NobelPrize in Physics'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Post-processing\n",
    "tweet_list[500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tokenize(tweet):\n",
    "    return [token for token in simple_preprocess(tweet) if token not in STOPWORDS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tweets = [tokenize(tweet) for tweet in tweet_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rt',\n",
       " 'uchicago',\n",
       " 'exploring',\n",
       " 'legacy',\n",
       " 'uchicago',\n",
       " 'scholar',\n",
       " 'maria',\n",
       " 'goeppert',\n",
       " 'mayer',\n",
       " 'winner',\n",
       " 'nobelprize',\n",
       " 'physics']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets[500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "frequency = defaultdict(int)\n",
    "for tweet in tweets:\n",
    "    for token in tweet:\n",
    "        frequency[token] += 1\n",
    "freq_series = pd.Series(frequency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "uchicago        32597\n",
       "rt              23076\n",
       "thaler           9449\n",
       "nobelprize       5355\n",
       "chicagobooth     4699\n",
       "richard          4632\n",
       "news             4322\n",
       "prize            4265\n",
       "economic         4177\n",
       "sciences         4171\n",
       "dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq_series.sort_values(ascending=False)[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From previous runs, calendar related items were found to confuse the algorithm. In addition two words are overly frequent and not helpful: 'rt' and 'uchicago'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "days = ['mon','tue','wed','thu','fri','sat','sun']\n",
    "months = ['jan', 'feb', 'mar','apr','may','jun',\\\n",
    "         'jul', 'aug', 'sep', 'oct', 'nov', 'dec']\n",
    "\n",
    "irrel = [\"rt\", \"uchicago\", \"amp\"]\n",
    "uncommon_words = [w[0] for w in frequency.items() if w[1]<5]\n",
    "two_letter = [w[0] for w in frequency.items() if len(w[0])< 3]\n",
    "\n",
    "removed = days + months + irrel + uncommon_words + two_letter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Process does take about 10-15 minutes, so the output is saved and loaded\n",
    "tweets_clean = [[token for token in tweet if token not in removed] for tweet in tweets]\n",
    "pickle_out = open(\"clean_final.pickle\", \"wb\")\n",
    "pickle.dump(tweets_clean, pickle_out)\n",
    "pickle_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_clean = pickle.load(open( \"clean_final.pickle\", \"rb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['exploring',\n",
       " 'legacy',\n",
       " 'scholar',\n",
       " 'maria',\n",
       " 'goeppert',\n",
       " 'mayer',\n",
       " 'winner',\n",
       " 'nobelprize',\n",
       " 'physics']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_clean[500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = corpora.Dictionary(tweets_clean)\n",
    "corpus = [dictionary.doc2bow(tweet) for tweet in tweets_clean]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run batch LDA and cross fingers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Runtime about 5 mins\n",
    "tweet_topics = LdaModel(corpus = corpus,\n",
    "                       id2word = dictionary,\n",
    "                       num_topics = 7,\n",
    "                       passes= 10)\n",
    "pickle_out2 = open(\"ffinalmodel.pickle\", \"wb\")\n",
    "pickle.dump(tweet_topics, pickle_out2)\n",
    "pickle_out2.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tweet_topics = pickle.load(open( \"ffinalmodel.pickle\", \"rb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 (0, '0.017*\"nuclear\" + 0.017*\"today\" + 0.014*\"berniesanders\" + 0.012*\"argonne\" + 0.009*\"fellow\" + 0.009*\"thanks\" + 0.009*\"reaction\" + 0.008*\"social\" + 0.008*\"fermilab\" + 0.008*\"chicago\"')\n",
      "1 (1, '0.016*\"new\" + 0.014*\"professor\" + 0.011*\"prof\" + 0.010*\"happy\" + 0.009*\"renato\" + 0.009*\"mariotti\" + 0.009*\"human\" + 0.008*\"time\" + 0.007*\"explains\" + 0.006*\"crime\"')\n",
      "2 (2, '0.165*\"thaler\" + 0.088*\"nobelprize\" + 0.084*\"chicagobooth\" + 0.081*\"richard\" + 0.079*\"prize\" + 0.078*\"sciences\" + 0.078*\"news\" + 0.077*\"economic\" + 0.075*\"awarded\" + 0.075*\"breaking\"')\n",
      "3 (3, '0.017*\"chicago\" + 0.014*\"uchicagolaw\" + 0.013*\"cancer\" + 0.011*\"research\" + 0.011*\"new\" + 0.010*\"makes\" + 0.009*\"robert\" + 0.008*\"data\" + 0.007*\"uchicagopress\" + 0.007*\"debate\"')\n",
      "4 (4, '0.067*\"uchicagogsu\" + 0.044*\"grad\" + 0.035*\"union\" + 0.019*\"yesgsu\" + 0.019*\"support\" + 0.019*\"final\" + 0.017*\"yes\" + 0.017*\"students\" + 0.017*\"room\" + 0.017*\"worker\"')\n",
      "5 (5, '0.017*\"chicago\" + 0.011*\"student\" + 0.011*\"new\" + 0.009*\"school\" + 0.009*\"program\" + 0.008*\"eveewing\" + 0.008*\"interview\" + 0.008*\"orientalinst\" + 0.008*\"phd\" + 0.007*\"research\"')\n",
      "6 (6, '0.024*\"president\" + 0.024*\"university\" + 0.019*\"zimmer\" + 0.017*\"chicago\" + 0.015*\"free\" + 0.013*\"bretstephensnyt\" + 0.012*\"speech\" + 0.011*\"students\" + 0.009*\"stands\" + 0.009*\"let\"')\n"
     ]
    }
   ],
   "source": [
    "for i, topic in enumerate(tweet_topics.print_topics(15)):\n",
    "    print (i, topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Package is in detached-head mode. Clone from Github, commit latest changes and run setup.py\n",
    "# https://github.com/bmabey/pyLDAvis\n",
    "import pyLDAvis.gensim as gensimvis\n",
    "import pyLDAvis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Note: if you're in the IPython notebook, pyLDAvis.show() is not the best command\n",
      "      to use. Consider using pyLDAvis.display(), or pyLDAvis.enable_notebook().\n",
      "      See more information at http://pyLDAvis.github.io/quickstart.html .\n",
      "\n",
      "You must interrupt the kernel to end this command\n",
      "\n",
      "Serving to http://127.0.0.1:8898/    [Ctrl-C to exit]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [10/Dec/2017 00:39:24] \"GET / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [10/Dec/2017 00:39:24] \"GET /LDAvis.css HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [10/Dec/2017 00:39:25] \"GET /d3.js HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [10/Dec/2017 00:39:25] \"GET /LDAvis.js HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "stopping Server...\n"
     ]
    }
   ],
   "source": [
    "vis_data = gensimvis.prepare(tweet_topics, corpus, dictionary)\n",
    "pyLDAvis.show(vis_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Determine time evolution of tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract all document-topic distritbutions to dictionnary\n",
    "document_key = list(tweet_df.date)\n",
    "document_topic = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "for doc_id in range(len(corpus)):\n",
    "    docbok = corpus[doc_id]\n",
    "    doc_topics = tweet_topics.get_document_topics(docbok, 0)\n",
    "    tmp = []\n",
    "    for topic_id, topic_prob in doc_topics:\n",
    "        tmp.append(topic_prob)\n",
    "    document_topic[document_key[doc_id]] = tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_dict(document_topic, orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = [\"Nuclear\", \"Professor_Crime\", \"Thaler_Nobel\", \"Cancer_Research\", \"Unionization\", \"Evening_Program\", \"Zimmer_FreeSpeech\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Nuclear</th>\n",
       "      <th>Professor_Crime</th>\n",
       "      <th>Thaler_Nobel</th>\n",
       "      <th>Cancer_Research</th>\n",
       "      <th>Unionization</th>\n",
       "      <th>Evening_Program</th>\n",
       "      <th>Zimmer_FreeSpeech</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Thu Jun 22 23:36:01 +0000 2017</th>\n",
       "      <td>0.015873</td>\n",
       "      <td>0.015903</td>\n",
       "      <td>0.460265</td>\n",
       "      <td>0.198421</td>\n",
       "      <td>0.015873</td>\n",
       "      <td>0.015873</td>\n",
       "      <td>0.277791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Thu Jun 22 23:42:33 +0000 2017</th>\n",
       "      <td>0.921976</td>\n",
       "      <td>0.012991</td>\n",
       "      <td>0.012987</td>\n",
       "      <td>0.013001</td>\n",
       "      <td>0.013017</td>\n",
       "      <td>0.013012</td>\n",
       "      <td>0.013016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Thu Jun 22 23:43:41 +0000 2017</th>\n",
       "      <td>0.263168</td>\n",
       "      <td>0.017885</td>\n",
       "      <td>0.017857</td>\n",
       "      <td>0.517804</td>\n",
       "      <td>0.017908</td>\n",
       "      <td>0.017959</td>\n",
       "      <td>0.147419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Thu Jun 22 23:48:16 +0000 2017</th>\n",
       "      <td>0.928487</td>\n",
       "      <td>0.011908</td>\n",
       "      <td>0.011905</td>\n",
       "      <td>0.011916</td>\n",
       "      <td>0.011930</td>\n",
       "      <td>0.011926</td>\n",
       "      <td>0.011929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Thu Jun 22 23:59:27 +0000 2017</th>\n",
       "      <td>0.028571</td>\n",
       "      <td>0.028571</td>\n",
       "      <td>0.028571</td>\n",
       "      <td>0.828571</td>\n",
       "      <td>0.028571</td>\n",
       "      <td>0.028571</td>\n",
       "      <td>0.028571</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Nuclear  Professor_Crime  Thaler_Nobel  \\\n",
       "Thu Jun 22 23:36:01 +0000 2017  0.015873         0.015903      0.460265   \n",
       "Thu Jun 22 23:42:33 +0000 2017  0.921976         0.012991      0.012987   \n",
       "Thu Jun 22 23:43:41 +0000 2017  0.263168         0.017885      0.017857   \n",
       "Thu Jun 22 23:48:16 +0000 2017  0.928487         0.011908      0.011905   \n",
       "Thu Jun 22 23:59:27 +0000 2017  0.028571         0.028571      0.028571   \n",
       "\n",
       "                                Cancer_Research  Unionization  \\\n",
       "Thu Jun 22 23:36:01 +0000 2017         0.198421      0.015873   \n",
       "Thu Jun 22 23:42:33 +0000 2017         0.013001      0.013017   \n",
       "Thu Jun 22 23:43:41 +0000 2017         0.517804      0.017908   \n",
       "Thu Jun 22 23:48:16 +0000 2017         0.011916      0.011930   \n",
       "Thu Jun 22 23:59:27 +0000 2017         0.828571      0.028571   \n",
       "\n",
       "                                Evening_Program  Zimmer_FreeSpeech  \n",
       "Thu Jun 22 23:36:01 +0000 2017         0.015873           0.277791  \n",
       "Thu Jun 22 23:42:33 +0000 2017         0.013012           0.013016  \n",
       "Thu Jun 22 23:43:41 +0000 2017         0.017959           0.147419  \n",
       "Thu Jun 22 23:48:16 +0000 2017         0.011926           0.011929  \n",
       "Thu Jun 22 23:59:27 +0000 2017         0.028571           0.028571  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"/Users/Orest/Desktop/Big Data and Text Analytics/FP/timed_tweets.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Graphs are produced with ggplot2 package in R."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
